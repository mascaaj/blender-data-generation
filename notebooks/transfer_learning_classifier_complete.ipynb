{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Image Classifier\n",
    "## What is this notebook?\n",
    "In this notebook we will train a neural network to classify the images in our synthetic dataset. It should be able to load an image and determine whether it contains an 'A', 'B', or 'C'.\n",
    "\n",
    "Note: This is different from an object detector, which can find multiple objects in a single image and put them in bounding boxes. A classifier only gives one label for the entire image.\n",
    "\n",
    "We could create a simple convolutional neural network from scratch, but in practice, it is much more common to start with a pre-trained neural network and re-train it to work with a new dataset. In order to do this re-training, called \"transfer learning\", we will start with a model on [TensorFlow Hub](https://www.tensorflow.org/hub) that has been trained on the ImageNet dataset. We will then add a couple layers to the end of the network and train it.\n",
    "\n",
    "## Inspiration\n",
    "This notebook and its code were inspired by the [Transfer learning with TensorFlow Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) tutorial. You can refer to that if you would like to learn more about it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "First we'll make sure TensorFlow and TensorFlow Hub are set up and that we import all of the modules we need.\n",
    "### Action Required\n",
    "- If you have not already installed tensorflow, tensorflow-hub, and matplotlib in your environment, do so here by uncommenting the appropriate lines\n",
    "- If you have a CUDA GPU and wan to use Tensorflow GPU, use the \"pip install tensorflow-gpu\" line, otherwise use \"pip install tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install tensorflow module (use the second line for Tensorflow GPU, if you have CUDA)\n",
    "#!pip install \"tensorflow>=2.0.0\"\n",
    "#!pip install \"tensorflow-gpu>=2.0.0\"\n",
    "\n",
    "# Install tensorflow_hub module\n",
    "#!pip install \"tensorflow_hub>=0.6.0\"\n",
    "\n",
    "# Install matplotlib\n",
    "#!pip install \"matplotlib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training, Validation, and Test Datasets\n",
    "We want to load our training, validation, and test images into ImageDataGenerators, which will be used to train/validate our TensorFlow model.\n",
    "\n",
    "### Action Required\n",
    "- Update the **train_dir**, **validation_dir**, & **test_dir** directory paths below to match where you've saved your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the IMAGE_SHAPE, train_dir, validation_dir, and test_dir\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "data_path = \n",
    "train_dir      = data_path + 'train'\n",
    "validation_dir = data_path + 'val'\n",
    "test_dir       = data_path + 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a training image generator and data generator\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a validation image generator and data generator\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a test image generator and data generator\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_image_generator.flow_from_directory(directory=test_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Images\n",
    "Now we'll display a few sample images from the Training and Validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_samples(data_gen, title):\n",
    "    # Make a lookup dictionary for class indexes\n",
    "    classes = dict()\n",
    "    for key, val in data_gen.class_indices.items():\n",
    "        classes[val] = key\n",
    "\n",
    "    # Get sample images and labels\n",
    "    sample_images, sample_labels = next(data_gen)\n",
    "\n",
    "    # Plot the images and labels\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for n in range(5):\n",
    "        plt.subplot(1,5,n+1)\n",
    "        plt.imshow(sample_images[n])\n",
    "        plt.title(classes[np.argmax(sample_labels[n])])\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(title)\n",
    "\n",
    "display_samples(train_data_gen, 'Sample Training Images')\n",
    "display_samples(validation_data_gen, 'Sample Validation Images')\n",
    "display_samples(test_data_gen, 'Sample Test Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the TensorFlow Model\n",
    "Now we'll create a new TensorFlow model based on the \"imagenet/mobilenet_v2_100_224/feature_vector\". This is a pre-trained model, but it has never been trained on 3D letters before, so we'll be retraining it for our purposes further below.\n",
    "\n",
    "Description: \"Feature vectors of images with MobileNet V2 (depth multiplier 1.00) trained on ImageNet (ILSVRC-2012-CLS).\"\n",
    "\n",
    "Source: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow model for classifying images\n",
    "num_classes = len(train_data_gen.class_indices)\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "                   trainable=False, input_shape=IMAGE_SHAPE+(3,)),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print out the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "In the block below, we'll train our neural network. In my experiments, I got .93 to .95 accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the train & val steps per epoch\n",
    "train_steps_per_epoch = np.ceil(train_data_gen.samples/train_data_gen.batch_size)\n",
    "val_steps_per_epoch = np.ceil(validation_data_gen.samples/validation_data_gen.batch_size)\n",
    "\n",
    "# Train the model\n",
    "epochs = 4\n",
    "history = model.fit(train_data_gen, epochs=epochs,\n",
    "                    steps_per_epoch=train_steps_per_epoch,\n",
    "                    validation_data=validation_data_gen,\n",
    "                    validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Now that our model is trained, let's run some of our test images through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a lookup numpy array for class names\n",
    "class_names = np.empty([len(test_data_gen.class_indices)], dtype=str, order='C')\n",
    "for key, val in test_data_gen.class_indices.items():\n",
    "    class_names[val] = key\n",
    "\n",
    "# Get a test batch of images and labels\n",
    "test_data_gen.reset()\n",
    "image_batch, label_batch = next(test_data_gen)\n",
    "\n",
    "# Predict the class of each image using our model\n",
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "label_id = np.argmax(label_batch, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Predictions\n",
    "Now we'll display predictions for our first 30 test images. If training worked properly, most of them should be correct, and the ones that fail should be fairly challenging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(min(30, len(image_batch))):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
    "    plt.title(predicted_label_batch[n].title(), color=color)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
